{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.261363636363637,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14204545454545456,
      "grad_norm": 22.944782257080078,
      "learning_rate": 2.916477272727273e-05,
      "loss": 0.8678,
      "step": 50
    },
    {
      "epoch": 0.2840909090909091,
      "grad_norm": 18.654895782470703,
      "learning_rate": 2.83125e-05,
      "loss": 0.49,
      "step": 100
    },
    {
      "epoch": 0.42613636363636365,
      "grad_norm": 12.631583213806152,
      "learning_rate": 2.746022727272727e-05,
      "loss": 0.3953,
      "step": 150
    },
    {
      "epoch": 0.5681818181818182,
      "grad_norm": 21.931697845458984,
      "learning_rate": 2.6607954545454548e-05,
      "loss": 0.3448,
      "step": 200
    },
    {
      "epoch": 0.7102272727272727,
      "grad_norm": 19.4027042388916,
      "learning_rate": 2.575568181818182e-05,
      "loss": 0.3133,
      "step": 250
    },
    {
      "epoch": 0.8522727272727273,
      "grad_norm": 15.491633415222168,
      "learning_rate": 2.490340909090909e-05,
      "loss": 0.2922,
      "step": 300
    },
    {
      "epoch": 0.9943181818181818,
      "grad_norm": 5.955834865570068,
      "learning_rate": 2.4051136363636366e-05,
      "loss": 0.2694,
      "step": 350
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 10.466796875,
      "learning_rate": 2.3198863636363637e-05,
      "loss": 0.2087,
      "step": 400
    },
    {
      "epoch": 1.2784090909090908,
      "grad_norm": 20.1652774810791,
      "learning_rate": 2.234659090909091e-05,
      "loss": 0.31,
      "step": 450
    },
    {
      "epoch": 1.4204545454545454,
      "grad_norm": 32.786643981933594,
      "learning_rate": 2.149431818181818e-05,
      "loss": 0.2285,
      "step": 500
    },
    {
      "epoch": 1.5625,
      "grad_norm": 13.398351669311523,
      "learning_rate": 2.0642045454545455e-05,
      "loss": 0.181,
      "step": 550
    },
    {
      "epoch": 1.7045454545454546,
      "grad_norm": 4.378372669219971,
      "learning_rate": 1.978977272727273e-05,
      "loss": 0.1543,
      "step": 600
    },
    {
      "epoch": 1.8465909090909092,
      "grad_norm": 27.16533088684082,
      "learning_rate": 1.89375e-05,
      "loss": 0.1842,
      "step": 650
    },
    {
      "epoch": 1.9886363636363638,
      "grad_norm": 5.639260292053223,
      "learning_rate": 1.808522727272727e-05,
      "loss": 0.1621,
      "step": 700
    },
    {
      "epoch": 2.1306818181818183,
      "grad_norm": 31.83134651184082,
      "learning_rate": 1.7232954545454547e-05,
      "loss": 0.1375,
      "step": 750
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 47.01355743408203,
      "learning_rate": 1.6380681818181818e-05,
      "loss": 0.143,
      "step": 800
    },
    {
      "epoch": 2.4147727272727275,
      "grad_norm": 6.854306221008301,
      "learning_rate": 1.552840909090909e-05,
      "loss": 0.1395,
      "step": 850
    },
    {
      "epoch": 2.5568181818181817,
      "grad_norm": 46.32545852661133,
      "learning_rate": 1.4676136363636364e-05,
      "loss": 0.114,
      "step": 900
    },
    {
      "epoch": 2.6988636363636362,
      "grad_norm": 23.308353424072266,
      "learning_rate": 1.3823863636363638e-05,
      "loss": 0.125,
      "step": 950
    },
    {
      "epoch": 2.840909090909091,
      "grad_norm": 19.642396926879883,
      "learning_rate": 1.2971590909090908e-05,
      "loss": 0.0996,
      "step": 1000
    },
    {
      "epoch": 2.9829545454545454,
      "grad_norm": 16.85621452331543,
      "learning_rate": 1.2119318181818182e-05,
      "loss": 0.1232,
      "step": 1050
    },
    {
      "epoch": 3.125,
      "grad_norm": 1.804339051246643,
      "learning_rate": 1.1267045454545454e-05,
      "loss": 0.0989,
      "step": 1100
    },
    {
      "epoch": 3.2670454545454546,
      "grad_norm": 67.30522155761719,
      "learning_rate": 1.0414772727272728e-05,
      "loss": 0.0745,
      "step": 1150
    },
    {
      "epoch": 3.409090909090909,
      "grad_norm": 10.34229564666748,
      "learning_rate": 9.5625e-06,
      "loss": 0.078,
      "step": 1200
    },
    {
      "epoch": 3.5511363636363638,
      "grad_norm": 25.673870086669922,
      "learning_rate": 8.710227272727273e-06,
      "loss": 0.1036,
      "step": 1250
    },
    {
      "epoch": 3.6931818181818183,
      "grad_norm": 1.1602575778961182,
      "learning_rate": 7.857954545454545e-06,
      "loss": 0.1089,
      "step": 1300
    },
    {
      "epoch": 3.8352272727272725,
      "grad_norm": 43.47816848754883,
      "learning_rate": 7.005681818181819e-06,
      "loss": 0.0739,
      "step": 1350
    },
    {
      "epoch": 3.9772727272727275,
      "grad_norm": 35.118431091308594,
      "learning_rate": 6.153409090909091e-06,
      "loss": 0.1102,
      "step": 1400
    },
    {
      "epoch": 4.119318181818182,
      "grad_norm": 4.7172369956970215,
      "learning_rate": 5.301136363636364e-06,
      "loss": 0.0938,
      "step": 1450
    },
    {
      "epoch": 4.261363636363637,
      "grad_norm": 46.3243293762207,
      "learning_rate": 4.448863636363636e-06,
      "loss": 0.0687,
      "step": 1500
    }
  ],
  "logging_steps": 50,
  "max_steps": 1760,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.7514758236143616e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
